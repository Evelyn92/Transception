cmd = /home/students/yiwei/yiwei_gitlab/EffFormer/train_trans.sh

# start directory
initialdir = /home/students/yiwei/yiwei_gitlab/EffFormer

# define output, error and log file 
output = /work/scratch/yiwei/last_week/log/model_$(cluster).$(Process)_out.log
error = /work/scratch/yiwei/last_week/log/model_$(cluster).$(Process)_err.log
log = /work/scratch/yiwei/last_week/log/model_$(cluster).$(Process)_log.log

# working environments
getenv        = True
environment   = "working_dir=/home/students/yiwei/yiwei_gitlab/EffFormer data_dir=/images/PublicDataset/Transunet_synaps/project_TransUNet/data/Synapse/"

# prevent jobs to be terminated 
on_exit_hold = (ExitBySignal == True) || (ExitCode != 0)
######################################################################
# Optional parameters
######################################################################

JobBatchName = MISSFormer_bl
nice_user = False

# Choose if job should run on cluster or workstation node. If unset job will run on eachy available node. Options are "cluster" or "workstations"
# requirements = POOL =="cluster"
#
# request a certain machine
# requirements = TARGET.Machine!="abatux.lfb.rwth-aachen.de"
#
# required GPU RAM (MB)

# requirements = (GPURAM > 15000)

# use only a gpu that supports half precision
# requirements = (HALF_PREC == 1)

#
# Attention: You can only set one requirement line. Add more requirements by using && e.g.
#
requirements = (GPURAM > 12000) && TARGET.Machine == "edison.lfb.rwth-aachen.de" || TARGET.Machine == "pc176.lfb.rwth-aachen.de" || TARGET.Machine == "pc38.lfb.rwth-aachen.de" || TARGET.Machine == "pc40.lfb.rwth-aachen.de" || TARGET.Machine == "pc44.lfb.rwth-aachen.de" || TARGET.Machine == "pc57.lfb.rwth-aachen.de" || TARGET.Machine == "pc33.lfb.rwth-aachen.de"  || TARGET.Machine == "pc60.lfb.rwth-aachen.de"  || TARGET.Machine == "pc63.lfb.rwth-aachen.de" 
#requirements = (GPURAM > 14000) && TARGET.Machine!="abatux.lfb.rwth-aachen.de"&& TARGET.Machine!="gauss.lfb.rwth-aachen.de" && TARGET.Machine!="pc81.lfb.rwth-aachen.de" && TARGET.Machine!="pc162.lfb.rwth-aachen.de" && TARGET.Machine!="pc167.lfb.rwth-aachen.de" && TARGET.Machine!="pc40.lfb.rwth-aachen.de" && TARGET.Machine!="pc44.lfb.rwth-aachen.de" && TARGET.Machine!="pc38.lfb.rwth-aachen.de" && TARGET.Machine!="pc61.lfb.rwth-aachen.de"


# required number of CPU cores
request_cpus = 0

# required number of GPUs
request_gpus = 1

# required CPU RAM
request_memory = 20 GB

# criterion after which to choose the machine
# e.g. `rank = memory` takes machine with largest RAM
rank = memory

# number of seconds to wait before executing job
# deferral_time = (CurrentTime + 1)


######################################################################
# Further preferences
######################################################################

# sync logfile to logfiles instead of copying them after finishing
stream_error = true
stream_output = true
should_transfer_files = IF_NEEDED

# run with user's account
run_as_owner = True
load_profile = True

# send email notifications (Always|Error|Complete|Never)
notify_user   = yiwei.jia@lfb.rwth-aachen.de
notification  = Never

# number of executions of this job
# queue 1

# if you want to use a range of arguments,
# you can add them like this, one set of argumetns per line
# version3:--dataset Synapse --base_lr 0.05 --max_epochs 500 --eval_interval 20 --model_name Transception_v3 --batch_size 24 --root_path /images/PublicDataset/Transunet_synaps/project_TransUNet/data/Synapse/train_npz --dil_conv=0
# version4:--dataset Synapse --base_lr 0.05 --max_epochs 500 --eval_interval 20 --model_name Transception_v4 --batch_size 24 --root_path /images/PublicDataset/Transunet_synaps/project_TransUNet/data/Synapse/train_npz --dil_conv=1
# version5: --dataset Synapse --base_lr 0.05 --max_epochs 400 --eval_interval 20 --model_name Transception_v5 --batch_size 24 --root_path /images/PublicDataset/Transunet_synaps/project_TransUNet/data/Synapse/train_npz --dil_conv=1 --output_dir output_v5
# scaleformer: --dataset Synapse --base_lr 0.05 --max_epochs 600 --eval_interval 20 --model_name ScaleFormer --batch_size 12 --root_path /images/PublicDataset/Transunet_synaps/project_TransUNet/data/Synapse/train_npz --dil_conv=0 --output_dir /home/students/yiwei/yiwei_gitlab/EffFormer/output_scale_600
#  --dataset Synapse --base_lr 0.05 --max_epochs 500 --eval_interval 20 --model_name Transception_v6 --batch_size 24 --root_path /images/PublicDataset/Transunet_synaps/project_TransUNet/data/Synapse/train_npz --dil_conv=1 --output_dir output_v6
# --dataset Synapse --base_lr 0.05 --max_epochs 500 --eval_interval 20 --model_name Transception_3branches_head2 --batch_size 24 --root_path /images/PublicDataset/Transunet_synaps/project_TransUNet/data/Synapse/train_npz --dil_conv=1 --output_dir /work/scratch/yiwei/Transception_3branches_mha/head_count2 --head_count=2
# --dataset Synapse --base_lr 0.05 --max_epochs 500 --eval_interval 20 --model_name Transception_3branches_head4 --batch_size 24 --root_path /images/PublicDataset/Transunet_synaps/project_TransUNet/data/Synapse/train_npz --dil_conv=1 --output_dir /work/scratch/yiwei/Transception_3branches_mha/head_count4 --head_count=4
queue 1 args from (    
   --dataset Synapse --base_lr 0.05 --max_epochs 400 --eval_interval 10 --if_bridge False --model_name MISSFormer_wo_br --batch_size 16 --root_path /images/PublicDataset/Transunet_synaps/project_TransUNet/data/Synapse/train_npz --output_dir /work/scratch/yiwei/last_week/MISSFormer_wo_br 
)
